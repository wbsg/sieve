<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Sieve – Data Fusion Policy Learner</title>
  <link rel="StyleSheet" href="stylesheets/style.css" type="text/css" media="screen"/>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>

<body>

  <div id="wbsg_navbar">
  	<div id="wbsg_navbar_projects">
  	<a href="http://dbpedia.org" title="DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web" >DBpedia</a>
  	<a href="http://spotlight.dbpedia.org/" title="DBpedia Spotlight is a tool for annotating DBpedia entities in text.">DBpedia Spotlight</a>
	<a href="http://d2rq.org/d2r-server" title="D2R Server is a tool for publishing the content of relational databases on the Semantic Web" >D2R Server</a>
	<a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/r2r/" title="R2R Framework &ndash; Translating RDF data from the Web to a target vocabulary" >R2R</a>
	<a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/silk/" title="The Silk framework is a tool for discovering relationships between data items within different Linked Data sources" >Silk</a>
	<a href="http://sieve.wbsg.de/" title="Sieve is a tool for assessing data quality and performing data fusion." class="wbsg_navbar_active_project">Sieve</a>
	<a href="http://ldif.wbsg.de/" title="LDIF &ndash; Linked Data Integration Framework translates heterogeneous Linked Data from the Web into a clean, local target representation while keeping track of data provenance" >LDIF</a>
	<a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/ng4j/" title="The Named Graphs API for Jena (NG4J) is an extension to the Jena Semantic Web framework for parsing, manipulating and serializing sets of Named Graphs" >NG4J</a>
	<a href="http://mes.github.com/marbles/" title="Marbles is a server-side application that formats Semantic Web content for XHTML clients using Fresnel lenses and formats" >Marbles</a>
  	<a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/wiqa/" title="The WIQA - Information Quality Assessment Framework is a set of software components that empowers information consumers to employ a wide range of different information quality assessment policies to filter information from the Web" >WIQA</a>
  	<a href="http://wifo5-03.informatik.uni-mannheim.de/pubby/" title="Pubby &ndash; A Linked Data Frontend for SPARQL Endpoints can be used to add Linked Data interfaces to SPARQL endpoints" >Pubby</a>
  	<a href="http://wifo5-03.informatik.uni-mannheim.de/bizer/rdfapi/" title="RAP &ndash; RDF API for PHP is a software package for parsing, querying, manipulating, serializing and serving RDF models" >RAP</a>
  	</div>
  	<!--div id="wbsg_navbar_intro">Open Source projects by the <a href="http://wbsg.de">Web-based Systems Group</a>:&nbsp;&nbsp;</div-->
	<div id="wbsg_navbar_intro">Open Source projects by the <a href="http://dws.informatik.uni-mannheim.de/">Data and Web Science Group</a>:&nbsp;&nbsp;</div>
  </div>
<!-- End WBSG navbar -->

<!--div id="logo" align="right">
	<a href="http://wbsg.de"><img src="http://ldif.wbsg.de/images/fu-logo.gif" alt="Freie Universität Berlin Logo" border="0"></a>
</div-->
<DIV id=logo><A href="http://dws.informatik.uni-mannheim.de/"><IMG src="images/logo_uni_en.gif" alt="Universit&auml;t Mannheim Logo"></A> </DIV>

<div id="header">
<h1 style="font-size: 200%;">Sieve – Data Fusion Policy Learner (FPL)</h1>
</div>

<div id="tagline">A Sieve module for automatically learning data fusion policies</div>

<div id="authors">
<a href="http://dws.informatik.uni-mannheim.de/en/people/researchers/dr-volha-bryl/">Volha Bryl</a><br>
<a href="http://dws.informatik.uni-mannheim.de/en/people/professors/prof-dr-christian-bizer/">Christian Bizer</a><br>
</div>

<div id="body-container">

<h2 id="news">News</h2>
<div>
 <ul>
  <li><b>05/02/2014</b>: <a href="#ref:WebQuality2014">Paper</a> about the FPL and the DBpedia data fusion use case will be presented at the <a href="http://www.dl.kuis.kyoto-u.ac.jp/webquality2014/">WebQuality workshop</a> of 
  <a href="http://www2014.kr/">WWW'2014</a>. [<a href="http://dws.informatik.uni-mannheim.de/fileadmin/lehrstuehle/ki/pub/Bryl_Bizer_webquality14.pdf">pdf</a>]</li>
  <li><b>19/12/2013</b>: First version realesed within <a href="http://ldif.wbsg.de/">LDIF 0.5.2</a>, check the <a href="https://github.com/wbsg/ldif/tree/master/ldif/ldif-modules/ldif-sieve/ldif-sieve-fpl">LDIF repository</a>.</li>
 </ul>
</div>

<h2 id="contents">Contents</h2>
<div>
 <ol class="toc">
  <li><a href="#about">About</a></li>
  <li><a href="#input">Input Specification</a></li>
  <li><a href="#output">Output</a><br></li>
  <li><a href="#start">Quick Start and Examples</a><br></li>
  <li><a href="#development">Source Code and Development</a></li>
  <li><a href="#feedback">Support and Feedback</a></li>
  <li><a href="#references">References</a></li>
  <li><a href="#acknowledgments">Acknowledgments</a></li>
 </ol>
</div>


<div>

<h2 id="about">1. About</h2>
  <p>
	<a href="http://sieve.wbsg.de/">Sieve</a> data quality assessment and data fusion framework provides a library of quality assessment scores and fusion functions, 
	and an XML-based input specification language to combine them. However, manually defining a fusion policy - that is, which fusion function and with what parameters 
	to use for which data attribute - requires certain domain knowledge and understanding of the input data, is time-consuming, and does not guarantee an optimal result. 
  </p>
  <p>
	Therefore, we introduce <b>Fusion Policy Learner</b>, an extension of Sieve that allows automatically selecting an optimal fusion function based on the gold standard.
	The user is still involved in the process as the list of possible fusion functions per property needs to be manually specified. 
  </p>
  <p>
    The learning algorithm implemented in the Fusion Policy Learner selects the fusion function that minimizes the error with respect to a <i>gold standard</i>. 
	The list of fusion functions and the respective quality assessment scores for each property are defined in the input specification, which is written 
	using the extended version of the XML-based Sieve specification language. 
  </p>
  <p>
	The learning algorithm first detects, based on the gold standard, whether the values to fuse are numeric or nominal; examples of nominal values are strings and URIs.
  </p>
  <p id="learning">
	Then for numeric properties one of the two learning strategies is applied: <b>(1)</b> a fusion function that minimizes the <i>mean absolute error</i> with respect to the gold 
	standard is selected, or <b>(2)</b> given a <i>maximum error threshold</i> (e.g. 5%), the function that maximizes the number of values that deviates from the gold standard 
	no more than by a threshold, is selected. In case of nominal values, the fusion function that produces the maximum number of exact matches with the gold standard is selected.
  </p>
  
  
<h2 id="input">2. Input Specification</h2>

<p>Below you see an example of input specification for the Fusion Policy Learner:</p>

<pre>
1 &lt;SieveFPL&gt;
2	&lt;Parameters&gt;
3		&lt;!--SelectionMethod name="MinAbsError"/--&gt;
4		&lt;SelectionMethod name="MaxCorrectValues" error="0.05"/&gt;
5	&lt;/Parameters&gt;
6	&lt;Input&gt;
7		&lt;GoldStandard&gt;gold\cities1000-Netherlands.gold.nt&lt;/GoldStandard&gt;
8		&lt;dumpLocation&gt;dumps-nl&lt;/dumpLocation&gt;	
9		&lt;SieveExec&gt;c:\ldif-0.5.2\bin\ldif.bat&lt;/SieveExec&gt;
10	&lt;/Input&gt;
11	&lt;Output&gt;
12		&lt;SieveSpec&gt;sieve-optimal\sieve_optimal.xml&lt;/SieveSpec&gt;		
13		&lt;FPLReport&gt;FPL_report.txt&lt;/FPLReport&gt;
14		&lt;!--FPLReport valmatrix = "true"&gt;FPL_report.txt&lt;/FPLReport--&gt;
15	&lt;/Output&gt;
16	&lt;Sieve xmlns="http://www4.wiwiss.fu-berlin.de/ldif/"&gt;
17		&lt;Prefixes&gt; 
18			&lt;Prefix id="dbpedia-owl" namespace="http://dbpedia.org/ontology/"/&gt;
19			&lt;Prefix id="ldif" namespace="http://www4.wiwiss.fu-berlin.de/ldif/"/&gt;
20			&lt;Prefix id="sieve" namespace="http://sieve.wbsg.de/vocab/"/&gt;
21			&lt;Prefix id="dbpedia-meta" namespace="http://dbpedia.org/metadata/"/&gt;
22		&lt;/Prefixes&gt;
23		&lt;QualityAssessment&gt;
24			&lt;AssessmentMetric id="sieve:authactivity"&gt;
25				&lt;ScoringFunction class="NormalizedCount"&gt;
26					&lt;Param name="maxCount" value="4250000"/&gt;
27					&lt;Input path="?GRAPH/dbpedia-meta:autheditcnt"/&gt;
28				&lt;/ScoringFunction&gt;
29			&lt;AssessmentMetric id="sieve:recency"&gt;
30				&lt;ScoringFunction class="TimeCloseness"&gt;
31					&lt;Param name="timeSpan" value="500"/&gt;
32					&lt;Input path="?GRAPH/dbpedia-meta:lastedit"/&gt;
33				&lt;/ScoringFunction&gt;
34			&lt;/AssessmentMetric&gt;
35		&lt;/QualityAssessment&gt;
36		&lt;Fusion&gt;
37			&lt;Class name="dbpedia-owl:PopulatedPlace"&gt;
38				&lt;Property name="dbpedia-owl:areaTotal"&gt;
39					&lt;FusionFunction class="KeepFirst" metric="sieve:recency"/&gt;
40					&lt;FusionFunction class="KeepFirst" metric="sieve:authactivity"/&gt;
41					&lt;FusionFunction class="Voting"/&gt;
42					&lt;FusionFunction class="Average"/&gt;
43				&lt;/Property&gt;
44				&lt;Property name="dbpedia-owl:populationTotal"&gt;
45					&lt;FusionFunction class="KeepFirst" metric="sieve:recency"/&gt;
46					&lt;FusionFunction class="Average"/&gt;
47					&lt;FusionFunction class="Maximum"/&gt;
48				&lt;/Property&gt;
49			&lt;/Class&gt;
50		&lt;/Fusion&gt;
51	&lt;/Sieve&gt;
52 &lt;/SieveFPL&gt;
</pre>

<p>
The root tag is &lt;SieveFPL&gt;, under which <b>4 elements</b> have to be specified: 
parameters of the learning algorithm (lines 2-5), 
input (lines 7-11) and output (lines 12-15) paths, 
and the extended Sieve specification (lines 16-20). 
</p>
<p>
The <b>&lt;SelectionMethod&gt;</b> element (lines 3-4) is used to specify the parameters of the learning algorithm for numeric data values. 
<i>MinAbsError</i> value of the <i>name</i> attribute corresponds to the 1st learning strategy (<a href="#learning">see above</a>), 
and <i>MaxCorrectValues</i> – to the 2nd one with <i>error</i> attribute defining the maximum error threshold.
</p>
<p>In the <b>&lt;Input&gt;</b> section the following parameters are specified:</p>
<ul>
    <li>&lt;GoldStandard&gt;: path to the gold standard dump, should be in N-TRIPLE format <i>(all paths are relative to the specification file path)</i>;</li>
	<li>&lt;dumpLocation&gt;: path to the input dumps, should be in N-QUAD format (the same requirement as for the input data in Sieve);</li>
	<li>&lt;SieveExec&gt;: path to the Sieve shell script or batch file.</li>
</ul>
<p>The <b>&lt;Output&gt;</b> section contains the following two paths to the output files generated by the tool:</p>
<ul>
    <li>&lt;SieveSpec&gt;: path to the resulting Sieve specification file;</li>
	<li>&lt;FPLReport&gt;: path to the report summarizing the learning process.</li>
</ul>
Optional <i>valmatrix</i> attribute of &lt;FPLReport&gt; (line 14 should be uncommented to replace line 13) allows including the <i>value matrix</i> to the report, that is, 
for each property a list of values (one per fusion function) for each subject URI is listed. For the sample specification above, the value matrix for <i>dbpedia-owl:populationTotal</i> 
(lines 45-47) is as follows. The values refer to <i>keep the most recent</i>, <i>average</i>, <i>maximum </i> and gold standard value, respectively; in the breakets the data source 
is specifyied  (language code in case of Wikipedia namespaces).
<pre>
http://dbpedia.org/resource/Buitenpost		5834 (en)	5777 (average)		5834 (en)	5764 (gold)
http://dbpedia.org/resource/Noordwijkerhout	15541 (it)	15460 (average)		15541 (ru)	15071 (gold)
http://dbpedia.org/resource/Harenkarspel	15922 (ru)	15973 (average)		16076 (it)	15941 (gold)
</pre>

<p>
<b>&lt;Sieve&gt;</b> element contains the extended or "redundant" Sieve specification: for each property a list of fusion functions is defined, 
and the FPL selects an optimal one from the list with respect to the gold standard. 
</p>
<p>
In <a href="#input">lines 39-42</a> 4 fusion functions - <i> keep the most recent value, keep the value added by the most active author, most frequent, average</i> - are specified for the <i>areaTotal</i> 
property of a populated place. The FPL chooses and puts into the final Sieve specification (<a href="#input">line 12</a>) only one of these functions, in accordance with the selection method defined in 
&lt;Parameters&gt;. 
</p>
<p>
In the current FPL version learning can be performed for only one class at a time, which means that learning an optimal fusion policy for the properties 
of e.g. <i>dbpedia-owl:CelestialBody</i> would require another specification file.
</p>


<h2 id="output">3. Output</h2>

The output of the tool consists of
<ul>
	<li>Sieve specification file (<a href="#input">line 12</a> defines the file name and location, relative to the FLP specification file) that can be used directly for data fusion with Sieve, </li>
	<li>FPL report file (<a href="#input">line 13</a> defines the file name and location), in which for each property the errors per fusion function are listed.</li>
</ul>

Below you see an extract of the report corresponding to the <a href="#input">FPL specification presented above</a>.

<pre>
*** Learning an optimal fusion function for dbpedia-owl:populationTotal property ***
Number of gold standard values = 493
According to the gold standard, dbpedia-owl:populationTotal is NUMERIC

Pool of fusion functions:
0 : &lt;FusionFunction class="KeepFirst" metric="sieve:recency"/&gt;
1 : &lt;FusionFunction class="Average"/&gt;
2 : &lt;FusionFunction class="Maximum"/&gt;

Errors per fusion function (functions identified by int ID):
0, mean absolute error : 0.02368750565457104, count : 493.0
0, number of 5.0% correct values : 318
1, mean absolute error : 0.022413082496238555, count : 493.0
1, number of 5.0% correct values : 301
2, mean absolute error : 0.021932866337685517, count : 493.0
2, number of 5.0% correct values : 329

MinAbsError: best fusion function ID, error %, count: 2, 2.193286633768552, 493.0
MaxCorrectValues: best fusion function ID, number of correct values : 2, 329
</pre>

<p>
The report contains the number of gold standard values for <i>dbpedia-owl:populationTotal</i> property (<i>493</i>), the detected property type (<i>numeric</i>), 
the list of the fusion functions as defined for <i>populationTotal</i> in the FPL specification. Fusion functions are assigned numeric IDs (<i>0, 1, 2</i>), 
which are then used to report errors for each functions with respect to the gold standard. 
</p>
<p>
For numeric properties, errors are reported for both learning methods: <i>MinAbsError</i> and <i>MaxCorrectValues</i> (with the default 5% threshold), and the optimal 
(referred  as "best" in the report) functions for both methods are listed. In our example, both selection methods resulted in <i>maximum</i> fusion function to be the optimal one. 
The final Sieve specification will include only the function which is optimal according to <i>MaxCorrectValues</i> method, as defined in <a href="#input">line 4 of our sample FPL specification</a>. 
</p>

<h2 id="start">4. Quick Start and Examples</h2>

<p>
In order to demonstrate the functionalities of the  Fusion Policy Learner, the <i>multilingual DBpedia</i> example is distributed with the LDIF binaries 
(<i>dbpedia-multilang</i> directory) and can be found in the <a href="https://github.com/wbsg/ldif/tree/master/ldif/examples/dbpedia-multilang/">LDIF repository</a>. 
The example aims at fusing data for the same city from multiple language editions of DBpedia. In the example directory you find the input specification (<i>SieveFPL.xml</i>) 
along with data and provenance metadata dumps (<i>dumps-3cities</i> and <i>dumps-nl</i> directories, use one of the two when specifying <i>dumpLocation</i> in 
<a href="#input">line 8</a>) and gold standard (in <i>gold</i> directory).
</p>

<p>
To run the FPL with the multilingual DBpedia example, download and unpack the LDIF binaries, and run
</p>
<i>java -jar lib\ldif-sieve-fpl-0.1.1-jar-with-dependencies.jar examples\dbpedia-multilang\SieveFPL.xml</i>
<p>
from the directory you have put the binaries to.
</p>


<h2 id="development">5. Source Code and Development</h2>

<p>The latest source code is available from the <a href="http://github.com/wbsg/ldif/">LDIF development page</a> on GitHub.</p>
<p>The framework can be used under the terms of the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache Software License</a>.</p>


<h2 id="feedback">6. Support and Feedback </h2>

<p>For questions and feedback please use the <a href="http://groups.google.com/group/ldif?hl=en">LDIF Google Group</a>.</p>


<h2 id="references">7. References</h2>

<div>
<ul>
<li id = "ref:WebQuality2014">Volha Bryl, Christian Bizer. <b>Learning Conflict Resolution Strategies for Cross-Language Wikipedia Data Fusion</b>. 
4th Joint WICOW/AIRWeb Workshop on Web Quality Workshop (WebQuality) @ WWW 2014. 
[<a href="http://dws.informatik.uni-mannheim.de/fileadmin/lehrstuehle/ki/pub/Bryl_Bizer_webquality14.pdf">pdf</a>]
</ul>
</div>

<h2 id="acknowledgments">8. Acknowledgments </h2>

<p>This work was supported by the EU FP7 grant <a href="http://lod2.eu/">LOD2 - Creating Knowledge out of Interlinked Data</a> (Grant No. 257943).</p>
<!--p>WooFunction icon set licensed under <a href="http://www.gnu.org/licenses/gpl.html">GNU General Public License</a>.</p-->

</div>

</div>

</body>
</html>
